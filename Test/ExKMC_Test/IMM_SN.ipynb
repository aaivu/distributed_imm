{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ExKMC.Tree import Tree\n",
    "from IPython.display import Image\n",
    "\n",
    "df = pd.read_csv(\"us_census_data_1990.csv\")\n",
    "\n",
    "num_duplicates = 20000000 // len(df) + 1\n",
    "\n",
    "df_large = pd.concat([df] * num_duplicates, ignore_index=True)\n",
    "\n",
    "df_large = df_large.iloc[:20000000]\n",
    "\n",
    "df_large.to_csv(\"us_census_data_1990_large.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 60 features and 6000000 data points...\n",
      "Runtime: 196.2352910041809 seconds, Tree saved as tree_features_60_datapoints_6000000.gv.png\n",
      "Testing with 60 features and 7000000 data points...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(15339) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 610.8592166900635 seconds, Tree saved as tree_features_60_datapoints_7000000.gv.png\n",
      "Testing with 60 features and 8000000 data points...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_full = df_large\n",
    "\n",
    "for col in X_full.columns:\n",
    "    X_full.loc[:, col] = pd.to_numeric(X_full[col], errors='coerce')\n",
    "\n",
    "X_full.fillna(X_full.mean(), inplace=True)\n",
    "\n",
    "def measure_runtime_and_save_tree(feature_count, data_points):\n",
    "    # Select first `feature_count` columns and `data_points` rows\n",
    "    X_subset = X_full.iloc[:data_points, :feature_count]\n",
    "\n",
    "    # Preprocess the dataset\n",
    "    categorical_cols = [col for col in X_subset.columns if X_subset[col].dtype == 'object']\n",
    "    numerical_cols = [col for col in X_subset.columns if X_subset[col].dtype != 'object']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),  # Standardize numerical features\n",
    "            ('cat', OneHotEncoder(), categorical_cols)  # One-hot encode categorical features\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_preprocessed = preprocessor.fit_transform(X_subset)\n",
    "\n",
    "    # Convert to DataFrame if needed\n",
    "    X_preprocessed = pd.DataFrame(X_preprocessed)\n",
    "\n",
    "    # Fit KMeans model\n",
    "    k = 10  # Number of clusters (IMM)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=43)\n",
    "\n",
    "    # Fit KMeans to the preprocessed data (important to avoid NotFittedError)\n",
    "    kmeans.fit(X_preprocessed)\n",
    "\n",
    "    # Measure the runtime for Tree creation\n",
    "    start_time = time.time()\n",
    "\n",
    "    tree = Tree(k=k)  # Initialize Tree model with number of clusters\n",
    "    tree.fit(X_preprocessed, kmeans)  # Fit the Tree model\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    tree_filename = f\"tree_features_{feature_count}_datapoints_{data_points}\"\n",
    "    tree.plot(filename=str(tree_filename), feature_names=list(X_subset.columns), view=False)\n",
    "\n",
    "\n",
    "    Image(filename=f'{tree_filename}.gv.png')\n",
    "\n",
    "    return end_time - start_time, tree_filename\n",
    "\n",
    "feature_counts = [60]\n",
    "data_point_sizes = [6000000,7000000,8000000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for feature_count in feature_counts:\n",
    "    for data_points in data_point_sizes:\n",
    "        print(f\"Testing with {feature_count} features and {data_points} data points...\")\n",
    "        runtime, tree_filename = measure_runtime_and_save_tree(feature_count, data_points)\n",
    "        print(f\"Runtime: {runtime} seconds, Tree saved as {tree_filename}.gv.png\")\n",
    "        results.append({\n",
    "            'Features': feature_count,\n",
    "            'Data Points': data_points,\n",
    "            'Runtime (seconds)': runtime,\n",
    "            'Tree Filename': tree_filename\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('runtime_and_tree_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
