{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql.functions import col\n",
    "from d_imm.histogram.histogram import DecisionTreeSplitFinder, Instance\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import pandas as pd\n",
    "from d_imm.imm_model import DistributedIMM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:14:36.625658Z",
     "start_time": "2025-02-09T08:14:34.285460Z"
    }
   },
   "id": "65885cfadc30944c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set Java environment variable if needed\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_261\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"C:\\\\Users\\\\saadha\\\\Desktop\\\\FYP-code\\\\GITHUB\\\\distributed-imm\\\\d-imm-python\\\\version-1\\\\venv\\\\Scripts\\\\python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"C:\\\\Users\\\\saadha\\\\Desktop\\\\FYP-code\\\\GITHUB\\\\distributed-imm\\\\d-imm-python\\\\version-1\\\\venv\\\\Scripts\\\\python.exe\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:14:36.640488Z",
     "start_time": "2025-02-09T08:14:36.628977Z"
    }
   },
   "id": "1059671c73eec2d5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set up Spark session\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"DecisionTreeSplitFinderExample\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:14:44.897251Z",
     "start_time": "2025-02-09T08:14:36.644036Z"
    }
   },
   "id": "165df8d171535520",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the Iris dataset from the UCI Machine Learning Repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "iris_df = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "# Convert the pandas DataFrame to a Spark DataFrame\n",
    "df_1 = spark.createDataFrame(iris_df)\n",
    "\n",
    "# Stack the dataset 5 times row-wise\n",
    "df = df_1\n",
    "for _ in range(5):\n",
    "    df = df.union(df_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:14:50.734086Z",
     "start_time": "2025-02-09T08:14:44.899489Z"
    }
   },
   "id": "fc9f304b835fab75",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "feature_df = assembler.transform(df)\n",
    "\n",
    "# Convert to RDD of Instances\n",
    "def to_instance(row):\n",
    "    features = [row.sepal_length, row.sepal_width, row.petal_length, row.petal_width]\n",
    "    label = 1.0 if row.species == \"Iris-setosa\" else 0.0  # Simplified binary label\n",
    "    weight = 1.0\n",
    "    return Instance(features=features, label=label, weight=weight)\n",
    "\n",
    "iris_rdd: RDD[Instance] = feature_df.select(\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\").rdd.map(to_instance)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:14:53.980599Z",
     "start_time": "2025-02-09T08:14:50.735147Z"
    }
   },
   "id": "65b85b1ebd034df1",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Instance(features=[5.1, 3.5, 1.4, 0.2], label=1.0, weight=1.0),\n Instance(features=[4.9, 3.0, 1.4, 0.2], label=1.0, weight=1.0),\n Instance(features=[4.7, 3.2, 1.3, 0.2], label=1.0, weight=1.0),\n Instance(features=[4.6, 3.1, 1.5, 0.2], label=1.0, weight=1.0),\n Instance(features=[5.0, 3.6, 1.4, 0.2], label=1.0, weight=1.0)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_rdd.take(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:15:05.408259Z",
     "start_time": "2025-02-09T08:14:53.986636Z"
    }
   },
   "id": "fcc5d0ff1590104a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0 (Continuous) splits:\n",
      "  Threshold = 4.85\n",
      "  Threshold = 5.05\n",
      "  Threshold = 5.15\n",
      "  Threshold = 5.45\n",
      "  Threshold = 5.65\n",
      "  Threshold = 5.95\n",
      "  Threshold = 6.15\n",
      "  Threshold = 6.35\n",
      "  Threshold = 6.65\n",
      "  Threshold = 6.95\n",
      "Feature 1 (Continuous) splits:\n",
      "  Threshold = 2.45\n",
      "  Threshold = 2.6500000000000004\n",
      "  Threshold = 2.8499999999999996\n",
      "  Threshold = 2.95\n",
      "  Threshold = 3.05\n",
      "  Threshold = 3.1500000000000004\n",
      "  Threshold = 3.25\n",
      "  Threshold = 3.3499999999999996\n",
      "  Threshold = 3.45\n",
      "  Threshold = 3.6500000000000004\n",
      "Feature 2 (Continuous) splits:\n",
      "  Threshold = 1.35\n",
      "  Threshold = 1.45\n",
      "  Threshold = 1.65\n",
      "  Threshold = 3.55\n",
      "  Threshold = 4.15\n",
      "  Threshold = 4.45\n",
      "  Threshold = 4.75\n",
      "  Threshold = 5.05\n",
      "  Threshold = 5.45\n",
      "  Threshold = 5.85\n",
      "Feature 3 (Continuous) splits:\n",
      "  Threshold = 0.15000000000000002\n",
      "  Threshold = 0.25\n",
      "  Threshold = 0.35\n",
      "  Threshold = 1.05\n",
      "  Threshold = 1.25\n",
      "  Threshold = 1.35\n",
      "  Threshold = 1.55\n",
      "  Threshold = 1.75\n",
      "  Threshold = 1.95\n",
      "  Threshold = 2.25\n"
     ]
    }
   ],
   "source": [
    "# Initialize DecisionTreeSplitFinder\n",
    "num_features = 4\n",
    "is_continuous = [True, True, True, True]  # All features are continuous\n",
    "is_unordered = [False, False, False, False]  # No categorical unordered features\n",
    "max_splits_per_feature = [10, 10, 10, 10]  # Max splits per feature\n",
    "max_bins = 32\n",
    "total_weighted_examples = float(750)\n",
    "seed = 42\n",
    "\n",
    "split_finder = DecisionTreeSplitFinder(\n",
    "    num_features=num_features,\n",
    "    is_continuous=is_continuous,\n",
    "    is_unordered=is_unordered,\n",
    "    max_splits_per_feature=max_splits_per_feature,\n",
    "    max_bins=max_bins,\n",
    "    total_weighted_examples=total_weighted_examples,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Find splits\n",
    "splits = split_finder.find_splits(input_rdd=iris_rdd)\n",
    "\n",
    "# Print the splits\n",
    "for fidx, feature_splits in enumerate(splits):\n",
    "    if is_continuous[fidx]:\n",
    "        print(f\"Feature {fidx} (Continuous) splits:\")\n",
    "        for s in feature_splits:\n",
    "            print(f\"  Threshold = {s.threshold}\")\n",
    "    else:\n",
    "        print(f\"Feature {fidx} (Categorical) splits:\")\n",
    "        for s in feature_splits:\n",
    "            print(f\"  Categories = {s.categories}\")\n",
    "        if not feature_splits:\n",
    "            print(\"  No splits found.\")\n",
    "\n",
    "# Stop Spark\n",
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:18:33.589925Z",
     "start_time": "2025-02-09T08:15:05.409373Z"
    }
   },
   "id": "a6e97987b151ca47",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-03T05:43:05.104548Z"
    }
   },
   "id": "2c48bdb6d0cba5af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
