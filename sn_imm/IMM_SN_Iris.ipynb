{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ExKMC.Tree import Tree\n",
    "from IPython.display import Image\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(\"iris_stacked_clustered_data_15000.csv\")\n",
    "\n",
    "# num_duplicates = 20000000 // len(df) + 1\n",
    "\n",
    "# df_large = pd.concat([df] * num_duplicates, ignore_index=True)\n",
    "\n",
    "# df_large = df_large.iloc[:20000000]\n",
    "\n",
    "# df_large.to_csv(\"us_census_data_1990_large.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count of the dataframe: 15150\n"
     ]
    }
   ],
   "source": [
    "row_count = df.shape[0]\n",
    "print(f\"Row count of the dataframe: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans_Wrapper:\n",
    "    def __init__(self, features, n_clusters, predictions, cluster_centers_):\n",
    "        self.predictions = predictions\n",
    "        self.features = features \n",
    "        self.cluster_centers_ = cluster_centers_\n",
    "        self.n_clusters = n_clusters\n",
    "    \n",
    "    def fit(self, X):\n",
    "        print(\"dummy fitting\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predictions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = np.array([\n",
    "    [5.88360656, 2.74098361, 4.38852459, 1.43442623], \n",
    "    [6.85384615, 3.07692308, 5.71538462, 2.05384615], \n",
    "    [5.006, 3.418, 1.464, 0.244]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_wrapper = KMeans_Wrapper(df ,3 , cluster_centers_= cluster_centers , predictions = df.iloc[:, -1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 4 features and 15000 data points...\n",
      "Runtime: 0.041790008544921875 seconds, Tree saved as tree_features_4_datapoints_15000.gv.png\n",
      "   Features  Data Points  Runtime (seconds)                     Tree Filename\n",
      "0         4        15000            0.04179  tree_features_4_datapoints_15000\n"
     ]
    }
   ],
   "source": [
    "X_full = df\n",
    "\n",
    "# for col in X_full.columns:\n",
    "#     X_full.loc[:, col] = pd.to_numeric(X_full[col], errors='coerce')\n",
    "\n",
    "# X_full.fillna(X_full.mean(), inplace=True)\n",
    "\n",
    "def measure_runtime_and_save_tree(feature_count, data_points):\n",
    "#     # Select first `feature_count` columns and `data_points` rows\n",
    "#     X_subset = X_full.iloc[:data_points, :feature_count]\n",
    "\n",
    "#     # Preprocess the dataset\n",
    "#     categorical_cols = [col for col in X_subset.columns if X_subset[col].dtype == 'object']\n",
    "#     numerical_cols = [col for col in X_subset.columns if X_subset[col].dtype != 'object']\n",
    "\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             ('num', StandardScaler(), numerical_cols),  # Standardize numerical features\n",
    "#             ('cat', OneHotEncoder(), categorical_cols)  # One-hot encode categorical features\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     X_preprocessed = preprocessor.fit_transform(X_subset)\n",
    "\n",
    "#     # Convert to DataFrame if needed\n",
    "#     X_preprocessed = pd.DataFrame(X_preprocessed)\n",
    "\n",
    "    # # Fit KMeans model\n",
    "    k = 3  # Number of clusters (IMM)\n",
    "        # kmeans = KMeans_Wrapper(n_clusters=k)\n",
    "\n",
    "        # # Fit KMeans to the preprocessed data (important to avoid NotFittedError)\n",
    "        # kmeans.fit(X_preprocessed)\n",
    "\n",
    "        # # Measure the runtime for Tree creation\n",
    "    start_time = time.time()\n",
    "\n",
    "    tree = Tree(k=k)  # Initialize Tree model with number of clusters\n",
    "    tree.fit(X_full, kmeans_wrapper)  # Fit the Tree model\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    tree_filename = f\"tree_features_{4}_datapoints_{15000}\"\n",
    "    tree.plot(filename=str(tree_filename), feature_names=list(X_full.columns), view=False)\n",
    "\n",
    "\n",
    "    Image(filename=f'{tree_filename}.gv.png')\n",
    "\n",
    "    return end_time - start_time, tree_filename\n",
    "\n",
    "feature_counts = [4]\n",
    "data_point_sizes = [15000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for feature_count in feature_counts:\n",
    "    for data_points in data_point_sizes:\n",
    "        print(f\"Testing with {feature_count} features and {data_points} data points...\")\n",
    "        runtime, tree_filename = measure_runtime_and_save_tree(feature_count, data_points)\n",
    "        print(f\"Runtime: {runtime} seconds, Tree saved as {tree_filename}.gv.png\")\n",
    "        results.append({\n",
    "            'Features': feature_count,\n",
    "            'Data Points': data_points,\n",
    "            'Runtime (seconds)': runtime,\n",
    "            'Tree Filename': tree_filename\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('runtime_and_tree_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 60 features and 100000 data points...\n",
      "KMeans results saved to kmeans_features_60_datapoints_100000.csv\n",
      "Runtime: 0.03 seconds, Tree saved as tree_features_60_datapoints_100000.gv.png\n",
      "Testing with 60 features and 500000 data points...\n",
      "KMeans results saved to kmeans_features_60_datapoints_500000.csv\n",
      "Runtime: 0.02 seconds, Tree saved as tree_features_60_datapoints_500000.gv.png\n",
      "Testing with 60 features and 1000000 data points...\n",
      "KMeans results saved to kmeans_features_60_datapoints_1000000.csv\n",
      "Runtime: 0.03 seconds, Tree saved as tree_features_60_datapoints_1000000.gv.png\n",
      "   Features  Data Points  Runtime (seconds)  \\\n",
      "0        60       100000           0.032372   \n",
      "1        60       500000           0.022983   \n",
      "2        60      1000000           0.025612   \n",
      "\n",
      "                         Tree Filename  \\\n",
      "0   tree_features_60_datapoints_100000   \n",
      "1   tree_features_60_datapoints_500000   \n",
      "2  tree_features_60_datapoints_1000000   \n",
      "\n",
      "                     KMeans Results Filename  \n",
      "0   kmeans_features_60_datapoints_100000.csv  \n",
      "1   kmeans_features_60_datapoints_500000.csv  \n",
      "2  kmeans_features_60_datapoints_1000000.csv  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import Image\n",
    "\n",
    "# Ensure Tree model is imported\n",
    "# from your_module import Tree  \n",
    "\n",
    "# Convert all columns to numeric\n",
    "X_full = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values with column means\n",
    "X_full.fillna(X_full.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "def measure_runtime_and_save_tree(feature_count, data_points):\n",
    "    # Select a subset of the dataset\n",
    "    X_subset = X_full.iloc[:data_points, :feature_count]\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = X_subset.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_cols = X_subset.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Define preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply transformations\n",
    "    X_preprocessed = preprocessor.fit_transform(X_subset)\n",
    "    \n",
    "    # Convert to DataFrame with feature names\n",
    "    preprocessed_feature_names = preprocessor.get_feature_names_out()\n",
    "    X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=preprocessed_feature_names)\n",
    "\n",
    "    # KMeans clustering\n",
    "    k = 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=43, n_init=10)\n",
    "    kmeans.fit(X_preprocessed)\n",
    "\n",
    "    # Add cluster assignments\n",
    "    X_preprocessed_df['Cluster'] = kmeans.labels_\n",
    "\n",
    "    # Save feature data with cluster labels\n",
    "    kmeans_results_filename = f\"kmeans_features_{feature_count}_datapoints_{data_points}.csv\"\n",
    "    X_preprocessed_df.to_csv(kmeans_results_filename, index=False)\n",
    "    print(f\"KMeans results saved to {kmeans_results_filename}\")\n",
    "\n",
    "    # Measure the runtime of tree creation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tree = Tree(k=k)\n",
    "    tree.fit(X_preprocessed, kmeans)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    # Save and visualize tree\n",
    "    tree_filename = f\"tree_features_{feature_count}_datapoints_{data_points}\"\n",
    "    tree.plot(filename=tree_filename, feature_names=X_subset.columns.tolist(), view=False)\n",
    "\n",
    "    # Display generated tree image\n",
    "    Image(filename=f'{tree_filename}.gv.png')\n",
    "\n",
    "    return end_time - start_time, tree_filename, kmeans_results_filename\n",
    "\n",
    "# Define test configurations\n",
    "feature_counts = [60]\n",
    "data_point_sizes = [100000, 500000, 1000000]\n",
    "results = []\n",
    "\n",
    "# Run tests and store results\n",
    "for feature_count in feature_counts:\n",
    "    for data_points in data_point_sizes:\n",
    "        print(f\"Testing with {feature_count} features and {data_points} data points...\")\n",
    "        runtime, tree_filename, kmeans_results_filename = measure_runtime_and_save_tree(feature_count, data_points)\n",
    "        print(f\"Runtime: {runtime:.2f} seconds, Tree saved as {tree_filename}.gv.png\")\n",
    "        results.append({\n",
    "            'Features': feature_count,\n",
    "            'Data Points': data_points,\n",
    "            'Runtime (seconds)': runtime,\n",
    "            'Tree Filename': tree_filename,\n",
    "            'KMeans Results Filename': kmeans_results_filename\n",
    "        })\n",
    "\n",
    "# Save runtime results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('runtime_and_tree_results.csv', index=False)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
