{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"]    = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]    = \"4\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ExKMC.Tree import Tree\n",
    "from IPython.display import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads used by OMP: 4\n",
      "Number of threads used by MKL: 4\n",
      "Number of threads used by OPENBLAS: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Number of threads used by OMP:\", os.environ.get(\"OMP_NUM_THREADS\"))\n",
    "print(\"Number of threads used by MKL:\", os.environ.get(\"MKL_NUM_THREADS\"))\n",
    "print(\"Number of threads used by OPENBLAS:\", os.environ.get(\"OPENBLAS_NUM_THREADS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"sub_data_2000000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 45 features and 100000 data points...\n",
      "Runtime: 2.6705679893493652 seconds, Tree saved as outputs_US/tree_features_45_datapoints_100000.gv.png\n",
      "Testing with 45 features and 1000000 data points...\n",
      "Runtime: 37.36707901954651 seconds, Tree saved as outputs_US/tree_features_45_datapoints_1000000.gv.png\n",
      "Testing with 45 features and 2000000 data points...\n",
      "Runtime: 69.77918791770935 seconds, Tree saved as outputs_US/tree_features_45_datapoints_2000000.gv.png\n",
      "   Features  Data Points  Runtime (seconds)  \\\n",
      "0        45       100000           2.670568   \n",
      "1        45      1000000          37.367079   \n",
      "2        45      2000000          69.779188   \n",
      "\n",
      "                                       Tree Filename  \n",
      "0  outputs_US/tree_features_45_datapoints_100000....  \n",
      "1  outputs_US/tree_features_45_datapoints_1000000...  \n",
      "2  outputs_US/tree_features_45_datapoints_2000000...  \n"
     ]
    }
   ],
   "source": [
    "output_folder = \"outputs_US\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "X_full = df\n",
    "\n",
    "for col in X_full.columns:\n",
    "    X_full.loc[:, col] = pd.to_numeric(X_full[col], errors='coerce')\n",
    "\n",
    "X_full.fillna(X_full.mean(), inplace=True)\n",
    "\n",
    "def measure_runtime_and_save_tree(feature_count, data_points):\n",
    "    X_subset = X_full.iloc[:data_points, :feature_count]\n",
    "\n",
    "    categorical_cols = [col for col in X_subset.columns if X_subset[col].dtype == 'object']\n",
    "    numerical_cols = [col for col in X_subset.columns if X_subset[col].dtype != 'object']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(), categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_preprocessed = preprocessor.fit_transform(X_subset)\n",
    "    X_preprocessed = pd.DataFrame(X_preprocessed)\n",
    "\n",
    "    k = 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=43)\n",
    "    kmeans.fit(X_preprocessed)\n",
    "\n",
    "    start_time = time.time()\n",
    "    tree = Tree(k=k)\n",
    "    tree.fit(X_preprocessed, kmeans)\n",
    "    end_time = time.time()\n",
    "\n",
    "    tree_filename = f\"tree_features_{feature_count}_datapoints_{data_points}\"\n",
    "    tree_filepath = os.path.join(output_folder, tree_filename)\n",
    "    tree.plot(filename=tree_filepath, feature_names=list(X_subset.columns), view=False)\n",
    "\n",
    "    Image(filename=f'{tree_filepath}.gv.png')\n",
    "\n",
    "    return end_time - start_time, tree_filepath\n",
    "\n",
    "feature_counts = [45]\n",
    "data_point_sizes = [100000, 1000000, 2000000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for feature_count in feature_counts:\n",
    "    for data_points in data_point_sizes:\n",
    "        print(f\"Testing with {feature_count} features and {data_points} data points...\")\n",
    "        runtime, tree_filepath = measure_runtime_and_save_tree(feature_count, data_points)\n",
    "        print(f\"Runtime: {runtime} seconds, Tree saved as {tree_filepath}.gv.png\")\n",
    "        results.append({\n",
    "            'Features': feature_count,\n",
    "            'Data Points': data_points,\n",
    "            'Runtime (seconds)': runtime,\n",
    "            'Tree Filename': tree_filepath + '.gv.png'\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(os.path.join(output_folder, 'runtime_and_tree_results.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
